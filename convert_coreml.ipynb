{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "torch171",
      "language": "python",
      "name": "torch171"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "test_faces.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacopoMangiavacchi/animegan2-coreml/blob/master/convert_coreml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNGnG2iQoWjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b823525-3525-40d6-e1aa-26650a896b7c"
      },
      "source": [
        "!pip install coremltools"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: coremltools in /usr/local/lib/python3.7/dist-packages (5.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.19.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (21.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.62.3)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->coremltools) (1.15.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (2.4.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTyeQkJiqIap",
        "outputId": "65bf14f2-8a73-4024-8162-be680db3a9d7"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import coremltools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 2.7.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.5.0 is the most recent version that has been tested.\n",
            "WARNING:root:Keras version 2.7.0 has not been tested with coremltools. You may run into unexpected errors. Keras 2.2.4 is the most recent version that has been tested.\n",
            "WARNING:root:Torch version 1.10.0+cu111 has not been tested with coremltools. You may run into unexpected errors. Torch 1.9.1 is the most recent version that has been tested.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-aipQlLkolf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bf4d44-cb3f-4e83-e995-a2af3036fc4f"
      },
      "source": [
        "!git clone https://github.com/jacopomangiavacchi/animegan2-coreml"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'animegan2-coreml'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 58 (delta 18), reused 34 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiZ9sJtVmOHy"
      },
      "source": [
        "os.chdir(f'./animegan2-coreml')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVFiEMWooRgm"
      },
      "source": [
        "from model import Generator\n",
        "\n",
        "device = 'cpu'\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "model = Generator().eval().to(device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quUonyi4kUha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8058f8f-aa68-4062-a6be-c2af6912e682"
      },
      "source": [
        "ckpt = torch.load(f\"weights/celeba_distill.pt\", map_location=device)\n",
        "# ckpt = torch.load(f\"weights/face_paint_512_v2.pt\", map_location=device)\n",
        "# ckpt = torch.load(f\"weights/paprika.pt\", map_location=device)\n",
        "model.load_state_dict(ckpt)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuAtLJWPrFBU",
        "outputId": "75c3d901-4db9-4d4c-995e-7ab853d0ab9e"
      },
      "source": [
        "image_sizes = [256, 512, 1024]\n",
        "\n",
        "for image_size in image_sizes:\n",
        "    image = torch.randn(1, 3, image_size, image_size)\n",
        "    output = model(image.to(device))\n",
        "\n",
        "    # scripted_model = torch.jit.script(model)\n",
        "    traced = torch.jit.trace(model, image)\n",
        "\n",
        "    image_input = coremltools.ImageType(name=\"input_1\", shape=(1, 3, image_size, image_size))\n",
        "\n",
        "    mlmodel = coremltools.converters.convert(\n",
        "      traced,\n",
        "      inputs=[image_input],\n",
        "    )\n",
        "\n",
        "    mlmodel.save(f'animegan2-celeba-distil-{image_size}.mlmodel')    \n",
        "    spec = coremltools.utils.load_spec(f\"animegan2-celeba-distil-{image_size}.mlmodel\")\n",
        "\n",
        "    output = spec.description.output[0]\n",
        "\n",
        "    output.type.imageType.colorSpace = coremltools.proto.FeatureTypes_pb2.ImageFeatureType.RGB\n",
        "    output.type.imageType.height = image_size\n",
        "    output.type.imageType.width = image_size\n",
        "\n",
        "    coremltools.utils.save_spec(spec, f\"animegan2-celeba-distil-{image_size}.mlmodel\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2359: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
            "Converting Frontend ==> MIL Ops: 100%|█████████▉| 295/296 [00:00<00:00, 475.23 ops/s]\n",
            "Running MIL Common passes:   6%|▌         | 2/34 [00:00<00:01, 18.72 passes/s]/usr/local/lib/python3.7/dist-packages/coremltools/converters/mil/mil/passes/name_sanitization_utils.py:129: UserWarning: Output, '457', of the source model, has been renamed to 'var_457' in the Core ML model.\n",
            "  warnings.warn(msg.format(var.name, new_name))\n",
            "Running MIL Common passes: 100%|██████████| 34/34 [00:00<00:00, 57.84 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 59.75 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 802/802 [00:00<00:00, 2113.85 ops/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|█████████▉| 295/296 [00:00<00:00, 461.87 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 34/34 [00:00<00:00, 56.29 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 63.78 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 802/802 [00:00<00:00, 2302.86 ops/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|█████████▉| 295/296 [00:00<00:00, 457.47 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 34/34 [00:00<00:00, 56.64 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 9/9 [00:00<00:00, 71.26 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 802/802 [00:00<00:00, 2251.61 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78mxCiWArpff"
      },
      "source": [
        "os.chdir(f'..')"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}